
> **Tr·ª£ l√Ω T√†i li·ªáu Th√¥ng minh** ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi RAG (Retrieval-Augmented Generation) Ti√™n ti·∫øn.

M·ªôt ·ª©ng d·ª•ng chatbot RAG hi·ªáu nƒÉng cao, cho ph√©p b·∫°n tr√≤ chuy·ªán v·ªõi c√°c t√†i li·ªáu PDF/DOCX c·ªßa m√¨nh b·∫±ng c√°ch s·ª≠ d·ª•ng LLM c·ª•c b·ªô (Local LLM). ƒê∆∞·ª£c x√¢y d·ª±ng v·ªõi giao di·ªán Glassmorphism tuy·ªát ƒë·∫πp v√† b·ªô nh·ªõ d√†i h·∫°n.

![Python](https://img.shields.io/badge/Python-3.10+-blue?style=flat-square&logo=python)
![Streamlit](https://img.shields.io/badge/Streamlit-1.53+-red?style=flat-square&logo=streamlit)
![Ollama](https://img.shields.io/badge/Ollama-Local_LLM-green?style=flat-square)
![Qdrant](https://img.shields.io/badge/Qdrant-Vector_DB-crimson?style=flat-square)

---

- **Frontend**: Streamlit (Custom CSS)
- **LLM**: Ollama + Qwen 2.5:14b
- **Embeddings**: BAAI/bge-m3 (1024 dims)
- **Reranker**: BAAI/bge-reranker-v2-m3
- **Vector DB**: Qdrant (Local persistent)
- **Memory**: Custom Mem0 implementation


### Y√™u c·∫ßu
- **Ollama** ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t v√† ch·∫°y

### C√°c b∆∞·ªõc c√†i ƒë·∫∑t
   ```powershell
   uv sync
   ```
   *Ho·∫∑c pip:* `pip install -r requirements.txt`

**T·∫£i Model cho Ollama**
   ```powershell
   ollama pull qwen2.5:14b
   ollama pull bge-m3
   ```

---

## üíª C√°ch Ch·∫°y ·ª®ng D·ª•ng

1. **Kh·ªüi ƒë·ªông Ollama Server**
   ```powershell
   ollama serve
   ```

2. **Ch·∫°y ·ª©ng d·ª•ng Streamlit**
   ```powershell
   uv run streamlit run app.py
   ```
   
3. **Truy c·∫≠p**: M·ªü tr√¨nh duy·ªát t·∫°i `http://localhost:8501`

```python
# C·∫•u h√¨nh LLM
LLM_MODEL_NAME = "qwen2.5:14b"    # ƒê·ªïi sang "qwen2.5:7b" n·∫øu m√°y y·∫øu
LLM_TEMP = 0.1                    # ƒê·ªô s√°ng t·∫°o (th·∫•p = ch√≠nh x√°c h∆°n)

# C·∫•u h√¨nh Chunking (Quan tr·ªçng cho hi·ªáu nƒÉng ingestion)
CHUNK_SIZE = 1000                 # K√≠ch th∆∞·ªõc m·ªói ƒëo·∫°n vƒÉn b·∫£n
CHUNK_OVERLAP = 200               # ƒê·ªô ch·ªìng l·∫∑p ƒë·ªÉ gi·ªØ ng·ªØ c·∫£nh

<p align="center">
</p>


